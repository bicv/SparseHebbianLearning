{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Hebbian Learning: toward a quantitative measure of the quality of filters\n",
    "\n",
    "We are interested here in learning the \"optimal\" components of a set of images (let's say some \"natural\", usual images). As there is no supervisor to guide the learning, this is called unsupervised learning. Our basic hypothesis to find the best (\"optimal\") components will be to assume that *a priori* the most sparse is more plausible. We will implement the derived algorithm in this set of scripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:56.624171Z",
     "start_time": "2018-05-16T08:20:56.606447Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.152177Z",
     "start_time": "2018-05-16T08:20:56.626239Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments\n",
    "\n",
    "To test and control for the role of different parameters, we will have a first object (in the [shl_experiments.py](https://github.com/bicv/SHL_scripts/blob/master/shl_scripts/shl_experiments.py) script) that controls a learning experiment. It contains all relevant parameters, but can also keep a trace of the history of some statistics. This is useful to compare the relative efficiency of the different solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.175023Z",
     "start_time": "2018-05-16T08:20:57.154521Z"
    }
   },
   "outputs": [],
   "source": [
    "do_random = True # draw new coeff at random\n",
    "do_random = False # draw new coeff with bootstrap resampling?\n",
    "\n",
    "do_high = False # do a surrogate with all coeffs\n",
    "do_high = True # do a surrogate with the higher coeffs\n",
    "\n",
    "do_double_shuffle = False # only shuffles with each sample \n",
    "do_double_shuffle = True # shuffle accross dictionary elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.374101Z",
     "start_time": "2018-05-16T08:20:57.177361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data extraction is locked data_cache/coding_test_data\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9c4831b73743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mshl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mindx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrecord_num_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlist_figures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tag = 'coding'\n",
    "homeo_methods = ['None', 'HAP', 'HEH']\n",
    "\n",
    "record_num_batches = 2**12\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "from shl_scripts.shl_experiments import SHL\n",
    "shl = SHL()\n",
    "data = shl.get_data(matname=tag + '_test')\n",
    "indx = np.random.permutation(data.shape[0])[:record_num_batches]\n",
    "\n",
    "list_figures = []\n",
    "\n",
    "dico = {}\n",
    "for homeo_method in homeo_methods:\n",
    "    print(15*'üê∂' + homeo_method[:3] + 15*'üê∂')\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "    dico[homeo_method] = shl.learn_dico(data=data, list_figures=list_figures, matname=tag + '_' + homeo_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coding\n",
    "\n",
    "The learning itself is done via a gradient descent but is highly dependent on the coding / decoding algorithm. This belongs to a another function (in the [shl_encode.py](https://github.com/bicv/SHL_scripts/blob/master/shl_scripts/shl_encode.py) script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.374925Z",
     "start_time": "2018-05-16T08:20:56.595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_encode import sparse_encode\n",
    "stick = np.arange(shl.n_dictionary)*shl.nb_quant\n",
    "P_cum_zeroeffect = np.linspace(0, 1, shl.nb_quant, endpoint=True)[np.newaxis, :] * np.ones((shl.n_dictionary, 1))\n",
    "\n",
    "for homeo_method in homeo_methods:\n",
    "    print(15*'üê∂' + homeo_method[:3] + 15*'üê∂')\n",
    "\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "    sparse_code = sparse_encode(data[indx, :], dico[homeo_method].dictionary, P_cum=dico[homeo_method].P_cum, C=shl.C, \n",
    "                                     l0_sparseness=shl.l0_sparseness, gain=None)   \n",
    "\n",
    "    from shl_scripts.shl_tools import print_stats\n",
    "    SD, SE = print_stats(data[indx, :], dico[homeo_method].dictionary, sparse_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new coefficients by shuffling and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.376741Z",
     "start_time": "2018-05-16T08:20:56.599Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_show = 30\n",
    "\n",
    "def shuffling(data, sparse_code, dico, N_show=N_show):\n",
    "    if do_random:\n",
    "        from shl_scripts.shl_encode import inv_quantile, inv_rescaling\n",
    "        sparse_code_bar = inv_rescaling(inv_quantile(dico.P_cum, np.random.rand(sparse_code.shape[0], sparse_code.shape[1])), C=shl.C)\n",
    "    else:\n",
    "        sparse_code = sparse_encode(data, dico.dictionary, P_cum=dico.P_cum, C=shl.C, \n",
    "                                     l0_sparseness=dico.n_dictionary, gain=None)   \n",
    "\n",
    "        sparse_code_bar = sparse_code.copy()\n",
    "        \n",
    "        #sparse_code_bar = sparse_code_bar.T\n",
    "        #np.random.shuffle(sparse_code_bar)\n",
    "        #sparse_code_bar = sparse_code_bar.T\n",
    "        sparse_code_bar = np.random.permutation(sparse_code_bar)\n",
    "        \n",
    "    if do_double_shuffle:\n",
    "        sparse_code_bar = np.random.permutation(sparse_code_bar.ravel()).reshape(sparse_code_bar.shape)\n",
    "        #np.random.shuffle(sparse_code_bar)\n",
    "    print('sparse_code_bar')\n",
    "    plt.matshow(sparse_code_bar[:N_show, :])\n",
    "    plt.show()\n",
    "\n",
    "    def threshold_mask(sparse_code, l0_sparseness, n_dictionary):\n",
    "        thr = np.percentile(sparse_code, 100 * (1 - l0_sparseness/n_dictionary), axis=1)\n",
    "        return (sparse_code>thr[:, np.newaxis])\n",
    "\n",
    "    sparse_code_bar_high = threshold_mask(sparse_code_bar, shl.l0_sparseness, shl.n_dictionary) * sparse_code_bar\n",
    "    print('sparse_code_bar_high')\n",
    "    plt.matshow(sparse_code_bar_high[:N_show, :])\n",
    "    plt.show()\n",
    "    return sparse_code_bar, sparse_code_bar_high\n",
    "\n",
    "def pipeline(sparse_code_bar, sparse_code_bar_high, dico, index, N_show=N_show):\n",
    "\n",
    "    if do_high:\n",
    "        patches_bar = sparse_code_bar_high @ dico.dictionary\n",
    "    else:\n",
    "        patches_bar = sparse_code_bar @ dico.dictionary\n",
    "\n",
    "        \n",
    "    SD = np.sqrt(np.mean(patches_bar**2, axis=1))\n",
    "\n",
    "    sparse_code_rec = sparse_encode(patches_bar, dico.dictionary, P_cum=dico.P_cum, C=shl.C, \n",
    "                                     l0_sparseness=shl.l0_sparseness, gain=None)   \n",
    "\n",
    "    print('bar: average non-zeros', np.count_nonzero(sparse_code_bar, axis=0)[:N_show])\n",
    "    print('bar_high: average non-zeros', np.count_nonzero(sparse_code_bar_high, axis=0)[:N_show])\n",
    "    print('rec: average non-zeros', np.count_nonzero(sparse_code_rec, axis=0)[:N_show])\n",
    "    \n",
    "    from shl_scripts import print_stats\n",
    "    SD, SE = print_stats(patches_bar, dico.dictionary, sparse_code_rec, verbose=False, display=True, N_show=N_show)\n",
    "    #plt.matshow(sparse_code_rec[:N_show, :])\n",
    "    plt.show()\n",
    "\n",
    "    print('mean deviation of coefficients = ', np.mean(np.abs(sparse_code_bar)), np.mean(np.abs(sparse_code_bar_high)), np.mean(np.abs(sparse_code_rec)))\n",
    "    print('mean deviation of coefficient errors = ', np.mean(np.abs(sparse_code_bar_high-sparse_code_rec)))\n",
    "\n",
    "    from shl_scripts.shl_encode import quantile, rescaling\n",
    "\n",
    "    q_rec = quantile(dico.P_cum, rescaling(sparse_code_rec, C=shl.C), stick, do_fast=False)\n",
    "    q_bar = quantile(dico.P_cum, rescaling(sparse_code_bar_high, C=shl.C), stick, do_fast=False)\n",
    "\n",
    "    print('mean deviation of quantiles = ', np.mean(np.abs(q_bar)))\n",
    "    print('mean deviation of quantiles = ', np.mean(np.abs(q_rec)))\n",
    "    print('total deviation of quantiles = ', np.mean(np.abs(q_bar-q_rec)))\n",
    "    print('ratio deviation of quantiles = ', np.mean(np.abs(q_bar-q_rec))/np.mean(np.abs(q_bar)))\n",
    "    aerror = np.mean(np.abs(q_bar-q_rec))/np.mean(np.abs(q_bar))\n",
    "\n",
    "    perror = 1 - np.mean( (sparse_code_bar>0) == (sparse_code_rec>0))\n",
    "    print('proba incorrect coefficients = ', perror)\n",
    "\n",
    "    perror_high = 1 - np.mean( (sparse_code_bar_high > 0) == (sparse_code_rec>0))\n",
    "    print('proba incorrect coefficients (high) = ', perror_high)\n",
    "    \n",
    "    return pd.DataFrame({'error':[(SD/SE).mean()],\n",
    "                               'aerror':[aerror],\n",
    "                               'perror':[perror],\n",
    "                               'perror_high':[perror_high]\n",
    "                                        },\n",
    "                                index=[index])\n",
    "\n",
    "record = None\n",
    "for homeo_method in homeo_methods:\n",
    "    print(42*'üê∂')\n",
    "    print(19*'üê∂' + '  ' + homeo_method + '  ' + 19*'üê∂')\n",
    "    print(42*'üê∂')\n",
    "\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "\n",
    "    sparse_code_bar, sparse_code_bar_high = shuffling(data[indx, :], sparse_code, dico[homeo_method])\n",
    "    record_ = pipeline(sparse_code_bar, sparse_code_bar_high, dico[homeo_method], index=homeo_method)\n",
    "    if record is None:\n",
    "        record = record_\n",
    "    else:\n",
    "        record = pd.concat((record, record_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.377814Z",
     "start_time": "2018-05-16T08:20:56.601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.378917Z",
     "start_time": "2018-05-16T08:20:56.603Z"
    }
   },
   "outputs": [],
   "source": [
    "from shl_scripts.shl_tools import get_perror\n",
    "for homeo_method in homeo_methods:\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "    print ('homeo_method', homeo_method, ', perrror=', get_perror(data[indx, :], dico[homeo_method].dictionary,  None,\n",
    "                            algorithm='mp', fit_tol=None,\n",
    "                             P_cum=dico[homeo_method].P_cum, gain=None,\n",
    "                             C=shl.C, do_sym=shl.do_sym,\n",
    "                             l0_sparseness=shl.l0_sparseness))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-16T08:20:57.380327Z",
     "start_time": "2018-05-16T08:20:56.606Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts, pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
