{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Hebbian Learning: toward a quantitative measure of the quality of filters\n",
    "\n",
    "We are interested here in learning the \"optimal\" components of a set of images (let's say some \"natural\", usual images). As there is no supervisor to guide the learning, this is called unsupervised learning. Our basic hypothesis to find the best (\"optimal\") components will be to assume that *a priori* the most sparse is more plausible. We will implement the derived algorithm in this set of scripts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:35.453696Z",
     "start_time": "2018-05-11T11:22:35.434792Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:35.986012Z",
     "start_time": "2018-05-11T11:22:35.456848Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments\n",
    "\n",
    "To test and control for the role of different parameters, we will have a first object (in the [shl_experiments.py](https://github.com/bicv/SHL_scripts/blob/master/shl_scripts/shl_experiments.py) script) that controls a learning experiment. It contains all relevant parameters, but can also keep a trace of the history of some statistics. This is useful to compare the relative efficiency of the different solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.006889Z",
     "start_time": "2018-05-11T11:22:35.988529Z"
    }
   },
   "outputs": [],
   "source": [
    "do_random = True # draw new coeff at random\n",
    "do_random = False # draw new coeff with bootstrap resampling?\n",
    "\n",
    "do_double_shuffle = True # shuffle accross dictionary elements\n",
    "do_double_shuffle = False # only shuffles \n",
    "\n",
    "l0_sparseness_noise = 200 #shl.n_dictionary #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.184369Z",
     "start_time": "2018-05-11T11:22:36.009101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶NonğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶\n",
      "ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶HAPğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶\n",
      "ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶HEHğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶ğŸ¶\n"
     ]
    }
   ],
   "source": [
    "tag = 'coding'\n",
    "homeo_methods = ['None', 'HAP', 'HEH']\n",
    "\n",
    "\n",
    "record_num_batches = 2**12\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "from shl_scripts.shl_experiments import SHL\n",
    "shl = SHL()\n",
    "data = shl.get_data(matname=tag)\n",
    "indx = np.random.permutation(data.shape[0])[:record_num_batches]\n",
    "\n",
    "list_figures = []\n",
    "\n",
    "dico = {}\n",
    "for homeo_method in homeo_methods:\n",
    "    print(15*'ğŸ¶' + homeo_method[:3] + 15*'ğŸ¶')\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "    dico[homeo_method] = shl.learn_dico(data=data, list_figures=list_figures, matname=tag + '_' + homeo_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coding\n",
    "\n",
    "The learning itself is done via a gradient descent but is highly dependent on the coding / decoding algorithm. This belongs to a another function (in the [shl_encode.py](https://github.com/bicv/SHL_scripts/blob/master/shl_scripts/shl_encode.py) script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.205047Z",
     "start_time": "2018-05-11T11:22:36.186301Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-6445ace43074>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-6445ace43074>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ==== shl_scripts.shl_encode import sparse_encode\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "shl_scripts.shl_encode import sparse_encode\n",
    "stick = np.arange(shl.n_dictionary)*shl.nb_quant\n",
    "P_cum_zeroeffect = np.linspace(0, 1, shl.nb_quant, endpoint=True)[np.newaxis, :] * np.ones((shl.n_dictionary, 1))\n",
    "\n",
    "for homeo_method in homeo_methods:\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "\n",
    "    for P_cum_rec, gain_rec in zip([None, P_cum_zeroeffect, dico[homeo_method].P_cum], [np.ones(shl.n_dictionary), None, None]):\n",
    "        sparse_code = sparse_encode(data[indx, :], dico[homeo_method].dictionary, P_cum=P_cum_rec, C=shl.C, \n",
    "                                     l0_sparseness=shl.l0_sparseness, gain=gain_rec)   \n",
    "\n",
    "        # from shl_scripts.shl_tools import print_stats\n",
    "        # SD, SE = print_stats(data[indx, :], dico[homeo_method].dictionary, sparse_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new coefficients by shuffling and decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.205954Z",
     "start_time": "2018-05-11T11:22:35.432Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def shuffling(data, sparse_code, dico, N_show=10):\n",
    "    if do_random:\n",
    "        from shl_scripts.shl_encode import inv_quantile, inv_rescaling\n",
    "        sparse_code_bar = inv_rescaling(inv_quantile(dico.P_cum, np.random.rand(sparse_code.shape[0], sparse_code.shape[1])), C=shl.C)\n",
    "    else:\n",
    "        sparse_code = sparse_encode(data, dico.dictionary, P_cum=dico.P_cum, C=shl.C, \n",
    "                                     l0_sparseness=l0_sparseness_noise, gain=None)   \n",
    "\n",
    "        sparse_code_bar = sparse_code.copy()\n",
    "        \n",
    "        sparse_code_bar = sparse_code_bar.T\n",
    "        np.random.shuffle(sparse_code_bar)\n",
    "        sparse_code_bar = sparse_code_bar.T\n",
    "        \n",
    "        if do_double_shuffle:\n",
    "            np.random.shuffle(sparse_code_bar)\n",
    "\n",
    "    plt.matshow(sparse_code_bar[:N_show, :])\n",
    "    plt.show()\n",
    "\n",
    "    def threshold(sparse_code, l0_sparseness):\n",
    "        thr = np.percentile(sparse_code, 100 * (1 - l0_sparseness/shl.n_dictionary ), axis=1)\n",
    "        return (sparse_code>thr[:, np.newaxis])\n",
    "\n",
    "    sparse_code_bar_high = threshold(sparse_code_bar, shl.l0_sparseness) * sparse_code_bar\n",
    "    plt.matshow(sparse_code_bar_high[:N_show, :])\n",
    "    plt.show()\n",
    "    return sparse_code_bar, sparse_code_bar_high\n",
    "\n",
    "def pipeline(sparse_code_bar, sparse_code_bar_high, dico, index, N_show=120):\n",
    "\n",
    "    patches_bar = sparse_code_bar @ dico.dictionary\n",
    "    SD = np.sqrt(np.mean(patches_bar**2, axis=1))\n",
    "\n",
    "\n",
    "    P_cum_rec = dico.P_cum\n",
    "    gain_rec = None\n",
    "\n",
    "    sparse_code_rec = sparse_encode(patches_bar, dico.dictionary, P_cum=P_cum_rec, C=shl.C, \n",
    "                                     l0_sparseness=shl.l0_sparseness, gain=gain_rec)   \n",
    "\n",
    "    print('average non-zeros', np.count_nonzero(sparse_code_bar, axis=0)[:N_show])\n",
    "    print('average non-zeros', np.count_nonzero(sparse_code_bar_high, axis=0)[:N_show])\n",
    "    print('average non-zeros', np.count_nonzero(sparse_code_rec, axis=0)[:N_show])\n",
    "    \n",
    "    from shl_scripts.shl_tools import print_stats\n",
    "    SD, SE = print_stats(patches_bar, dico.dictionary, sparse_code_rec, verbose=False, display=True)\n",
    "    #plt.matshow(sparse_code_rec[:N_show, :])\n",
    "    plt.show()\n",
    "\n",
    "    print('mean deviation of coefficients = ', np.mean(np.abs(sparse_code_bar)), np.mean(np.abs(sparse_code_bar_high)), np.mean(np.abs(sparse_code_rec)))\n",
    "    print('total deviation of coefficients = ', np.mean(np.abs(sparse_code_bar_high-sparse_code_rec)))\n",
    "\n",
    "    from shl_scripts.shl_encode import quantile, rescaling\n",
    "\n",
    "    q_rec = quantile(dico.P_cum, rescaling(sparse_code_rec, C=shl.C), stick, do_fast=False)\n",
    "    q_bar = quantile(dico.P_cum, rescaling(sparse_code_bar_high, C=shl.C), stick, do_fast=False)\n",
    "\n",
    "    print('mean deviation of quantiles = ', np.mean(np.abs(q_bar)))\n",
    "    print('mean deviation of quantiles = ', np.mean(np.abs(q_rec)))\n",
    "    print('total deviation of quantiles = ', np.mean(np.abs(q_bar-q_rec)))\n",
    "    print('ratio deviation of quantiles = ', np.mean(np.abs(q_bar-q_rec))/np.mean(np.abs(q_bar)))\n",
    "    aerror = np.mean(np.abs(q_bar-q_rec))/np.mean(np.abs(q_bar))\n",
    "\n",
    "    perror = 1 - np.mean( (sparse_code_bar>0) == (sparse_code_rec>0))\n",
    "    print('proba incorrect coefficients = ', perror)\n",
    "\n",
    "    perror_high = 1 - np.mean( (sparse_code_bar_high > 0) == (sparse_code_rec>0))\n",
    "    print('proba incorrect coefficients (strong) = ', perror_high)\n",
    "    \n",
    "    return pd.DataFrame({'error':[(SD/SE).mean()],\n",
    "                               'aerror':[aerror],\n",
    "                               'perror':[perror],\n",
    "                               'perror_high':[perror_high]\n",
    "                                        },\n",
    "                                index=[index])\n",
    "\n",
    "record = None\n",
    "for homeo_method in homeo_methods:\n",
    "    shl = SHL(homeo_method=homeo_method)\n",
    "\n",
    "    sparse_code_bar, sparse_code_bar_high = shuffling(data[indx, :], sparse_code, dico[homeo_method])\n",
    "    record_ = pipeline(sparse_code_bar, sparse_code_bar_high, dico[homeo_method], index=homeo_method)\n",
    "    if record is None:\n",
    "        record = record_\n",
    "    else:\n",
    "        record = pd.concat((record, record_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.207556Z",
     "start_time": "2018-05-11T11:22:35.435Z"
    }
   },
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.208989Z",
     "start_time": "2018-05-11T11:22:35.438Z"
    }
   },
   "outputs": [],
   "source": [
    "record_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T11:22:36.210296Z",
     "start_time": "2018-05-11T11:22:35.441Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts, pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
